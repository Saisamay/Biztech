<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Video Proctoring System</title>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/blazeface"></script>
    <style>
        body { text-align: center; font-family: Arial, sans-serif; }
        canvas { position: absolute; top: 0; left: 0; }
        #warning { color: red; font-size: 18px; margin-top: 10px; }
        .container { position: relative; display: inline-block; }
        video { border: 2px solid black; }
    </style>
</head>
<body>
    <h1>Video Proctoring System</h1>

    <!-- Video Source Selection -->
    <button onclick="startWebcam()">Use Webcam</button>
    <input type="file" id="videoUpload" accept="video/*">

    <div class="container">
        <video id="video" width="640" height="480" autoplay controls></video>
        <canvas id="canvas" width="640" height="480"></canvas>
    </div>
    <p id="warning"></p>

    <script>
        const video = document.getElementById("video");
        const canvas = document.getElementById("canvas");
        const ctx = canvas.getContext("2d");
        const warningText = document.getElementById("warning");
        const videoUpload = document.getElementById("videoUpload");

        let modelLoaded = false;
        let model = null;

        // Load BlazeFace Model
        async function loadModel() {
            model = await blazeface.load();
            modelLoaded = true;
            console.log("BlazeFace Model Loaded");
        }

        // Start Webcam Stream
        async function startWebcam() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                video.srcObject = stream;
                video.play();
            } catch (error) {
                console.error("Error accessing webcam:", error);
            }
        }

        // Handle Video File Upload
        videoUpload.addEventListener("change", (event) => {
            const file = event.target.files[0];
            if (file) {
                const objectURL = URL.createObjectURL(file);
                video.src = objectURL;
                video.play();
            }
        });

        // Face Detection
        async function detectFace() {
            if (!modelLoaded) return;

            setInterval(async () => {
                if (video.readyState >= 2) {  // Ensure video is playing
                    const faces = await model.estimateFaces(video, false);
                    ctx.clearRect(0, 0, canvas.width, canvas.height);
                    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

                    // Handle warnings
                    if (faces.length === 0) {
                        warningText.innerText = "No face detected! Stay in front of the camera.";
                    } else if (faces.length > 1) {
                        warningText.innerText = "Multiple faces detected! Possible cheating.";
                    } else {
                        warningText.innerText = ""; // No warnings
                    }

                    // Draw bounding boxes
                    faces.forEach(face => {
                        ctx.beginPath();
                        ctx.rect(
                            face.topLeft[0],
                            face.topLeft[1],
                            face.bottomRight[0] - face.topLeft[0],
                            face.bottomRight[1] - face.topLeft[1]
                        );
                        ctx.strokeStyle = "red";
                        ctx.lineWidth = 2;
                        ctx.stroke();
                    });
                }
            }, 500);
        }

        loadModel();
        detectFace();
    </script>
</body>
</html>
